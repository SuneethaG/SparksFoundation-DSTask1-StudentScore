plot(varImp(ridge, scale = TRUE))
#LASSO REGRESSION
set.seed(1234)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
lasso
plot(lasso)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 0.2, length = 5)), trControl = custom)
plot(lasso)
plot(lasso$finalModel, xvar = "lambda", label = TRUE)
plot(lasso$finalModel, xvar = "dev", label = TRUE)
plot(varImp(lasso, scale = TRUE))
#ELASTIC NET REGRESSION
set.seed (1234)
elastic <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = seq(0,1, length = 10),
lambda = seq(0.0001, 1, length = 5)), trControl = custom)
plot(elastic)
elastic
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
summary (compare)
## BEST MODEL
ridge$bestTune
lasso$bestTune
elastic$bestTune
## to examine the coefficients
best <- ridge$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(ridge, "finalmodel.rds")
final <-readRDS("finalmodel.rds")
print(final)
##### PREDICTION
P1 <- predict(final, train)
sqrt(mean((train$SOLD.PRICE -P1)^2))
P2<- predict(final, test)
sqrt(mean((test$SOLD.PRICE-P2)^2))
#Importing Raw data from the Excel
data <- read.csv("clipboard",sep = "\t",header = TRUE)
View(data)
#Adding Dummy variables for Categorical variables
L25<- recode(data$AGE,"'1'= 1; '2'= 0;'3'= 0;", as.factor=TRUE)
B25_35<- recode(data$AGE,"'1'= 0; '2'= 1;'3'= 0;", as.factor=TRUE)
P_SA<- recode(data$COUNTRY,"'SA'= 1; 'BAN'= 0;'IND'= 0;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_IND<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 0;'IND'= 1;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_Aus<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 0;'IND'= 0;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=1;'ENG'=0;", as.factor=TRUE)
P_Oth_Cont<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 1;'IND'= 0;'WI'= 1;'SL'= 1;'NZ'= 1;'PAK'= 1;'ZIM'= 1;'AUS'=0;'ENG'=1;", as.factor=TRUE)
P_Team_Mult<- recode(data$TEAM,"'CSK'= 0; 'CSK+'= 1;'DC'= 0;'DC+'= 1;'DD'= 0;'DD+'= 1;'KXIP'= 0;'KXIP+'= 1;'KKR'=0;'KKR+'=1;'MI'=0;'MI+'=1;'RCB'=0;'RCB+'=1;'RR'=0;'RR+'=1;", as.factor=TRUE)
P_Bat<- recode(data$PLAYING.ROLE,"'Batsman'= 1; 'W. Keeper'= 1;'Allrounder'= 0;'Bowler'=0;", as.factor=TRUE)
P_Bowler<- recode(data$PLAYING.ROLE,"'Batsman'= 0; 'W. Keeper'= 0;'Allrounder'= 0;'Bowler'=1;", as.factor=TRUE)
P_2008<- recode(data$AUCTION.YEAR,"2008= 1; 2009= 0;2010= 0;2011=0;", as.factor=TRUE)
P_2010<- recode(data$AUCTION.YEAR,"2008= 0; 2009= 0;2010= 1 ;2011=0;", as.factor=TRUE)
P_2011<- recode(data$AUCTION.YEAR,"2008= 0; 2009= 0;2010= 0;2011=1;", as.factor=TRUE)
data1<-subset(data,select=-c(COUNTRY,TEAM,PLAYING.ROLE,PLAYER.NAME,Sl.NO.,AGE,AUCTION.YEAR))
data2<-cbind(data1,L25,B25_35,P_IND,P_SA,P_Aus,P_Oth_Cont,P_Team_Mult,P_Bat,P_Bowler,P_2008,P_2010,P_2011)
## converting captaincy column from int to factor
data1$CAPTAINCY.EXP<-as.factor(data$CAPTAINCY.EXP)
View(data1)
##run linear regression
model<-lm(SOLD.PRICE~.,data=data2)
summary(model)
#check the correlation between all the numerical predictors using corrplot package
citation("corrplot")
data12 <- subset(data1,select=-c(CAPTAINCY.EXP,BASE.PRICE,SOLD.PRICE))
#check the correlation between all the numerical predictors using corrplot package
data12 <- subset(data1,select=-c(CAPTAINCY.EXP,BASE.PRICE,SOLD.PRICE))
View(data12)
corrplot(cor(data12))
#Feature selection using backward regression
step<- step(model,direction = "backward")
data3<-subset(data2,select=c(P_Bat,P_Bowler,ODI.SR.BL,P_2010,P_2011,L25,B25_35,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_SA,P_IND,P_Oth_Cont,WKTS,BASE.PRICE,SOLD.PRICE))
View(data3)
set.seed(1234)
index <- sample(2,nrow(data3), replace =TRUE,p=c(0.7,0.3))
train<-data3[index==1,]
test<-data3[index==2,]
custom <-trainControl (method= "repeatedcv", number=10,repeats= 5)
set.seed (1234)
linear<-train(SOLD.PRICE~.,train,method="lm",trControl= custom)
linear$results
summary(linear)
data3<-subset(data2,select=c(P_Bat,P_Bowler,ODI.SR.BL,P_2010,P_2011,L25,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_SA,P_IND,P_Oth_Cont,WKTS,BASE.PRICE,SOLD.PRICE))
View(data3)
set.seed(1234)
index <- sample(2,nrow(data3), replace =TRUE,p=c(0.7,0.3))
train<-data3[index==1,]
test<-data3[index==2,]
custom <-trainControl (method= "repeatedcv", number=10,repeats= 5)
set.seed (1234)
linear<-train(SOLD.PRICE~.,train,method="lm",trControl= custom)
linear$results
summary(linear)
data3<-subset(data2,select=c(P_Bat,P_Bowler,ODI.SR.BL,P_2008,P_2010,P_2011,L25,B25_35,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_SA,P_IND,P_Oth_Cont,WKTS,BASE.PRICE,SOLD.PRICE))
View(data3)
set.seed(1234)
index <- sample(2,nrow(data3), replace =TRUE,p=c(0.7,0.3))
train<-data3[index==1,]
test<-data3[index==2,]
custom <-trainControl (method= "repeatedcv", number=10,repeats= 5)
set.seed (1234)
linear<-train(SOLD.PRICE~.,train,method="lm",trControl= custom)
linear$results
summary(linear)
#Ridge regression with variable with feature selection
set.seed (1234)
ridge <- train (SOLD.PRICE~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 0, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
ridge
plot(ridge)
plot(ridge$finalModel, xvar = "lambda", label = TRUE)
plot(ridge$finalModel, xvar = "dev", label = TRUE)
plot(varImp(ridge, scale = TRUE))
#LASSO REGRESSION
set.seed(1234)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
lasso
plot(lasso)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 0.2, length = 5)), trControl = custom)
plot(lasso)
plot(lasso$finalModel, xvar = "lambda", label = TRUE)
plot(lasso$finalModel, xvar = "dev", label = TRUE)
plot(varImp(lasso, scale = TRUE))
#ELASTIC NET REGRESSION
set.seed (1234)
elastic <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = seq(0,1, length = 10),
lambda = seq(0.0001, 1, length = 5)), trControl = custom)
plot(elastic)
elastic
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
summary (compare)
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
summary (compare)
## BEST MODEL
ridge$bestTune
lasso$bestTune
elastic$bestTune
## to examine the coefficients
best <- ridge$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(ridge, "finalmodel.rds")
final <-readRDS("finalmodel.rds")
print(final)
##### PREDICTION
P1 <- predict(final, train)
sqrt(mean((train$SOLD.PRICE -P1)^2))
P2<- predict(final, test)
sqrt(mean((test$SOLD.PRICE-P2)^2))
#data3<-subset(data2,select=c(P_Bat,P_Bowler,ODI.SR.BL,P_2008,P_2010,P_2011,L25,B25_35,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_SA,P_IND,P_Oth_Cont,WKTS,BASE.PRICE,SOLD.PRICE))
data2<-subset(data1,select=c(P_Bowler,ODI.SR.BL,P_2011,L25,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_IND,WKTS,BASE.PRICE,SOLD.PRICE))
View(data3)
set.seed(1234)
index <- sample(2,nrow(data3), replace =TRUE,p=c(0.7,0.3))
train<-data3[index==1,]
test<-data3[index==2,]
custom <-trainControl (method= "repeatedcv", number=10,repeats= 5)
set.seed (1234)
linear<-train(SOLD.PRICE~.,train,method="lm",trControl= custom)
linear$results
summary(linear)
#Ridge regression with variable with feature selection
set.seed (1234)
ridge <- train (SOLD.PRICE~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 0, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
ridge
plot(ridge)
plot(ridge$finalModel, xvar = "lambda", label = TRUE)
plot(ridge$finalModel, xvar = "dev", label = TRUE)
plot(varImp(ridge, scale = TRUE))
#LASSO REGRESSION
set.seed(1234)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
lasso
plot(lasso)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 0.2, length = 5)), trControl = custom)
plot(lasso)
plot(lasso$finalModel, xvar = "lambda", label = TRUE)
plot(lasso$finalModel, xvar = "dev", label = TRUE)
plot(varImp(lasso, scale = TRUE))
#ELASTIC NET REGRESSION
set.seed (1234)
elastic <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = seq(0,1, length = 10),
lambda = seq(0.0001, 1, length = 5)), trControl = custom)
plot(elastic)
elastic
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
summary (compare)
## BEST MODEL
ridge$bestTune
lasso$bestTune
elastic$bestTune
## to examine the coefficients
best <- ridge$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(ridge, "finalmodel.rds")
final <-readRDS("finalmodel.rds")
print(final)
##### PREDICTION
P1 <- predict(final, train)
sqrt(mean((train$SOLD.PRICE -P1)^2))
P2<- predict(final, test)
sqrt(mean((test$SOLD.PRICE-P2)^2))
#Importing Raw data from the Excel
data <- read.csv("clipboard",sep = "\t",header = TRUE)
View(data)
#Adding Dummy variables for Categorical variables
L25<- recode(data$AGE,"'1'= 1; '2'= 0;'3'= 0;", as.factor=TRUE)
B25_35<- recode(data$AGE,"'1'= 0; '2'= 0;'3'= 1;", as.factor=TRUE)
P_SA<- recode(data$COUNTRY,"'SA'= 1; 'BAN'= 0;'IND'= 0;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_IND<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 0;'IND'= 1;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_Oth_Cont<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 1;'IND'= 0;'WI'= 1;'SL'= 1;'NZ'= 1;'PAK'= 1;'ZIM'= 1;'AUS'=0;'ENG'=1;", as.factor=TRUE)
P_Team_Mult<- recode(data$TEAM,"'CSK'= 0; 'CSK+'= 1;'DC'= 0;'DC+'= 1;'DD'= 0;'DD+'= 1;'KXIP'= 0;'KXIP+'= 1;'KKR'=0;'KKR+'=1;'MI'=0;'MI+'=1;'RCB'=0;'RCB+'=1;'RR'=0;'RR+'=1;", as.factor=TRUE)
P_Bat<- recode(data$PLAYING.ROLE,"'Batsman'= 1; 'W. Keeper'= 1;'Allrounder'= 0;'Bowler'=0;", as.factor=TRUE)
P_Bowler<- recode(data$PLAYING.ROLE,"'Batsman'= 0; 'W. Keeper'= 0;'Allrounder'= 0;'Bowler'=1;", as.factor=TRUE)
P_2008<- recode(data$AUCTION.YEAR,"2008= 1; 2009= 0;2010= 0;2011=0;", as.factor=TRUE)
P_2010<- recode(data$AUCTION.YEAR,"2008= 0; 2009= 0;2010= 1 ;2011=0;", as.factor=TRUE)
P_2011<- recode(data$AUCTION.YEAR,"2008= 0; 2009= 0;2010= 0;2011=1;", as.factor=TRUE)
data1<-subset(data,select=-c(COUNTRY,TEAM,PLAYING.ROLE,PLAYER.NAME,Sl.NO.,AGE,AUCTION.YEAR))
data2<-cbind(data1,L25,B25_35,P_IND,P_SA,P_Oth_Cont,P_Team_Mult,P_Bat,P_Bowler,P_2008,P_2010,P_2011)
## converting captaincy column from int to factor
data1$CAPTAINCY.EXP<-as.factor(data$CAPTAINCY.EXP)
View(data1)
##run linear regression
model<-lm(SOLD.PRICE~.,data=data2)
summary(model)
#Feature selection using backward regression
step<- step(model,direction = "backward")
data3<-subset(data2,select=c(P_Bowler,ODI.SR.BL,P_2011,L25,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_IND,WKTS,BASE.PRICE,SOLD.PRICE))
View(data3)
set.seed (1234)
linear<-train(SOLD.PRICE~.,train,method="lm",trControl= custom)
linear$results
summary(linear)
#Ridge regression with variable with feature selection
set.seed (1234)
ridge <- train (SOLD.PRICE~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 0, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
ridge
plot(ridge$finalModel, xvar = "lambda", label = TRUE)
plot(ridge$finalModel, xvar = "dev", label = TRUE)
plot(varImp(ridge, scale = TRUE))
#LASSO REGRESSION
set.seed(1234)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
lasso
plot(lasso)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 0.2, length = 5)), trControl = custom)
plot(lasso)
plot(lasso$finalModel, xvar = "lambda", label = TRUE)
plot(lasso$finalModel, xvar = "dev", label = TRUE)
plot(varImp(lasso, scale = TRUE))
plot(varImp(lasso, scale = TRUE))
#ELASTIC NET REGRESSION
set.seed (1234)
elastic <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = seq(0,1, length = 10),
lambda = seq(0.0001, 1, length = 5)), trControl = custom)
plot(elastic)
elastic
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
summary (compare)
## BEST MODEL
ridge$bestTune
lasso$bestTune
elastic$bestTune
## to examine the coefficients
best <- ridge$finalModel
## to examine the coefficients
best <- Lasso$finalModel
## to examine the coefficients
best <- lasso$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(ridge, "finalmodel.rds")
## to examine the coefficients
best <- lasso$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(lasso, "finalmodel.rds")
final <-readRDS("finalmodel.rds")
print(final)
##### PREDICTION
P1 <- predict(final, train)
sqrt(mean((train$SOLD.PRICE -P1)^2))
P2<- predict(final, test)
sqrt(mean((test$SOLD.PRICE-P2)^2))
## to examine the coefficients
best <- lasso$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(lasso, "finalmodel.rds")
coef(best, s = lasso$bestTune$lambda)
saveRDS(lasso, "finalmodel.rds")
final <-readRDS("finalmodel.rds")
print(final)
## to examine the coefficients
best <- lasso$finalModel
coef(best, s = lasso$bestTune$lambda)
##### PREDICTION
P1 <- predict(final, train)
sqrt(mean((train$SOLD.PRICE -P1)^2))
P2<- predict(final, test)
sqrt(mean((test$SOLD.PRICE-P2)^2))
#Importing Raw data from the Excel
data <- read.csv("clipboard",sep = "\t",header = TRUE)
View(data)
#Adding Dummy variables for Categorical variables
L25<- recode(data$AGE,"'1'= 1; '2'= 0;'3'= 0;", as.factor=TRUE)
B25_35<- recode(data$AGE,"'1'= 0; '2'= 0;'3'= 1;", as.factor=TRUE)
P_SA<- recode(data$COUNTRY,"'SA'= 1; 'BAN'= 0;'IND'= 0;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_IND<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 0;'IND'= 1;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_Oth_Cont<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 1;'IND'= 0;'WI'= 1;'SL'= 1;'NZ'= 1;'PAK'= 1;'ZIM'= 1;'AUS'=0;'ENG'=1;", as.factor=TRUE)
library(car)
library(caret)
library(corrplot)
library(glmnet)
library(psych)
#Adding Dummy variables for Categorical variables
L25<- recode(data$AGE,"'1'= 1; '2'= 0;'3'= 0;", as.factor=TRUE)
B25_35<- recode(data$AGE,"'1'= 0; '2'= 0;'3'= 1;", as.factor=TRUE)
P_SA<- recode(data$COUNTRY,"'SA'= 1; 'BAN'= 0;'IND'= 0;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_IND<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 0;'IND'= 1;'WI'= 0;'SL'= 0;'NZ'= 0;'PAK'= 0;'ZIM'= 0;'AUS'=0;'ENG'=0;", as.factor=TRUE)
P_Oth_Cont<- recode(data$COUNTRY,"'SA'= 0; 'BAN'= 1;'IND'= 0;'WI'= 1;'SL'= 1;'NZ'= 1;'PAK'= 1;'ZIM'= 1;'AUS'=0;'ENG'=1;", as.factor=TRUE)
P_Team_Mult<- recode(data$TEAM,"'CSK'= 0; 'CSK+'= 1;'DC'= 0;'DC+'= 1;'DD'= 0;'DD+'= 1;'KXIP'= 0;'KXIP+'= 1;'KKR'=0;'KKR+'=1;'MI'=0;'MI+'=1;'RCB'=0;'RCB+'=1;'RR'=0;'RR+'=1;", as.factor=TRUE)
P_Bat<- recode(data$PLAYING.ROLE,"'Batsman'= 1; 'W. Keeper'= 1;'Allrounder'= 0;'Bowler'=0;", as.factor=TRUE)
P_Bowler<- recode(data$PLAYING.ROLE,"'Batsman'= 0; 'W. Keeper'= 0;'Allrounder'= 0;'Bowler'=1;", as.factor=TRUE)
P_2008<- recode(data$AUCTION.YEAR,"2008= 1; 2009= 0;2010= 0;2011=0;", as.factor=TRUE)
P_2010<- recode(data$AUCTION.YEAR,"2008= 0; 2009= 0;2010= 1 ;2011=0;", as.factor=TRUE)
P_2011<- recode(data$AUCTION.YEAR,"2008= 0; 2009= 0;2010= 0;2011=1;", as.factor=TRUE)
data1<-subset(data,select=-c(COUNTRY,TEAM,PLAYING.ROLE,PLAYER.NAME,Sl.NO.,AGE,AUCTION.YEAR))
data2<-cbind(data1,L25,B25_35,P_IND,P_SA,P_Oth_Cont,P_Team_Mult,P_Bat,P_Bowler,P_2008,P_2010,P_2011)
## converting captaincy column from int to factor
data1$CAPTAINCY.EXP<-as.factor(data$CAPTAINCY.EXP)
View(data1)
View (data2)
str(data2)
##run linear regression
model<-lm(SOLD.PRICE~.,data=data2)
summary(model)
data12 <- subset(data1,select=-c(CAPTAINCY.EXP,BASE.PRICE,SOLD.PRICE))
View(data12)
corrplot(cor(data12))
#Feature selection using backward regression
step<- step(model,direction = "backward")
data3<-subset(data2,select=c(P_Bowler,ODI.SR.BL,P_2011,L25,ODI.WKTS,RUNS.S,T.RUNS,ODI.RUNS.S,P_IND,WKTS,BASE.PRICE,SOLD.PRICE))
View(data3)
set.seed(1234)
index <- sample(2,nrow(data3), replace =TRUE,p=c(0.7,0.3))
train<-data3[index==1,]
test<-data3[index==2,]
custom <-trainControl (method= "repeatedcv", number=15,repeats= 5)
set.seed (1234)
linear<-train(SOLD.PRICE~.,train,method="lm",trControl= custom)
linear$results
summary(linear)
#Ridge regression with variable with feature selection
set.seed (1234)
ridge <- train (SOLD.PRICE~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 0, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
ridge
plot(ridge)
plot(ridge$finalModel, xvar = "lambda", label = TRUE)
plot(ridge$finalModel, xvar = "dev", label = TRUE)
plot(varImp(ridge, scale = TRUE))
#LASSO REGRESSION
set.seed(1234)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 1, length = 5)), trControl = custom)
lasso
plot(lasso)
lasso <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = 1, lambda = seq(0.0001, 0.2, length = 5)), trControl = custom)
plot(lasso)
plot(lasso$finalModel, xvar = "lambda", label = TRUE)
plot(lasso$finalModel, xvar = "dev", label = TRUE)
plot(varImp(lasso, scale = TRUE))
#ELASTIC NET REGRESSION
set.seed (1234)
elastic <- train (SOLD.PRICE ~., train, method = "glmnet", tuneGrid = expand.grid(alpha = seq(0,1, length = 10),
lambda = seq(0.0001, 1, length = 5)), trControl = custom)
plot(elastic)
elastic
## COMPARE THE MODEL
modellist <- list (linear = linear, lasso = lasso, ridge = ridge, elastic = elastic)
compare <- resamples(modellist)
summary (compare)
## BEST MODEL
ridge$bestTune
lasso$bestTune
elastic$bestTune
## to examine the coefficients
best <- ridge$finalModel
coef(best, s = ridge$bestTune$lambda)
saveRDS(ridge, "finalmodel.rds")
final <-readRDS("finalmodel.rds")
print(final)
##### PREDICTION
P1 <- predict(final, train)
sqrt(mean((train$SOLD.PRICE -P1)^2))
P2<- predict(final, test)
sqrt(mean((test$SOLD.PRICE-P2)^2))
bankdata <- read.csv("clipboard",sep = "\t",header = TRUE)
library(caret)
library(car)
bankdata <- read.csv("clipboard",sep = "\t",header = TRUE)
View(bankdata)
str(bankdata)
bankdata$C.MANIPULATOR <- as.factor(bankdata$C.MANIPULATOR)
#Removed Company ID and categorical variable for which dummy is available
bankdata <- bankdata[,c(-1,-10)]
head(bankdata)
#Remove Highly Correlated variables
corrplot(cor(bankdata[-9]))
library(corrplot)
#Remove Highly Correlated variables
corrplot(cor(bankdata[-9]))
bankdata <- bankdata[,-1]
View(bankdata)
## PERFORM LOGISTIC REGRESSION
set.seed(1234)
myIndex <- createDataPartition(bankdata$C.MANIPULATOR,p = 0.60, list = FALSE)
traindata <- bankdata[myIndex,]
testdata <- bankdata[-myIndex,]
set.seed(1234)
reg <- glm(C.MANIPULATOR ~ ., family = binomial, data = traindata)
summary(reg)
## BUILD PREDICTED RESPONSE AND DEVELOP CONFUSION MATRIX FOR TRAIN DATA (MODEL_1)
reg_class <- predict (reg, traindata, type = "response")
reg_class
head(reg_class)
pred <- ifelse (reg_class >0.50, 1,0)
table <- table (Predicted  = pred, Actual = traindata$C.MANIPULATOR)
table
data1 <- read.csv("clipboard", sep = "\t", header = TRUE)
attach(data1)
data1$total <- Dislike+Like
attach(data1)
data1$prob <- Like/total
attach(data1)
plot (prob~Age, pch = 16, xlab = "Age")
data1$total <- Dislike+Like
attach(data1)
data1$prob <- Like/total
attach(data1)
plot (prob~Age, pch = 16, xlab = "Age")
logreg2 <- glm(Preference~Age, family = binomial, data = data)
summary(logreg2)
exp(coef(logreg2))
data <- read.csv ("clipboard", sep = "\t", header = T)
logreg <- glm(Preference~Gender, family = binomial, data = data)
summary(logreg)
exp(coef(logreg))
logreg2 <- glm(Preference~Age, family = binomial, data = data)
summary(logreg2)
exp(coef(logreg2))
data <- read.csv ("clipboard", sep = "\t", header = T)
logreg <- glm(Preference~Gender, family = binomial, data = data)
summary(logreg)
logreg2 <- glm(Preference~Age, family = binomial, data = data)
summary(logreg2)
exp(coef(logreg2))
#Example data.xlsx
logreg2 <- glm(Preference~Age-1, family = binomial, data = data)
summary(logreg2)
data <- read.csv ("clipboard", sep = "\t", header = TRUE)
#see the strucure of the data
str (data)
library(car)
library(caTools)
library(readxl)
#Importing the Data
studentsData <- read_xlsx("StudentGradesandScores.xlsx")
#Setting the working directory
setwd("D:/GRIP")
#Importing the Data
studentsData <- read_xlsx("StudentGradesandScores.xlsx")
#Check if data is imported correct
View(studentsData)
str(studentsData)
head(studentsData)
tail(studentsData)
#Split the data into Training and Testing
split = sample.split(studentsData$Hours,SplitRatio = 0.7)
split
trainingSet <- subset(studentsData, split == TRUE)
testSet <- subset(studentsData, split == FALSE)
#Fitting linear regression to the training set
lm = lm(studentsData$Hours ~ studentsData$Scores, data = studentsData)
summary(lm)
coef(lm)
yPred <- predict(lm,testSet)
yPred
summary(yPred)
#Score expected for a student who studies for 9.25hrs/day
-0.006285579 + (0.097480295) * 9.25
0.8954071 *100
#Score expected for a student who studies for 9.25hrs/day
a <- data.frame(x = 9.25)
result <-  predict(lm,a)
print(result)
yPred <- predict(lm,testSet)
yPred
summary(yPred)
#Fitting linear regression to the training set
lm = lm(studentsData$Hours ~ studentsData$Scores, data = trainingSet)
summary(lm)
yPred <- predict(lm,testSet)
yPred
summary(yPred)
coef(yPred)
?predict
plot(studentsData$Hours,studentsData$Scores,data=studentsData)
plot(studentsData$Hours,studentsData$Scores)
warnings()
#Score expected for a student who studies for 9.25hrs/day
yPRed <- predict(lm,9.25)
